{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = 1  # player 1 plays\n",
    "P2 = -1  # player 2 plays\n",
    "N = 3 # NxN board\n",
    "LEARNING_RATE = 0.5\n",
    "GAMMA = 0.9\n",
    "EXPLORE_RATE = 0.2\n",
    "EXPLORE_DECAY = 0.9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, size, p1, p2):\n",
    "        self.size = size\n",
    "        self.board = np.zeros((self.size, self.size), dtype=int)\n",
    "        self.player1 = p1\n",
    "        self.player2 = p2\n",
    "    \n",
    "    def get_free_positions(self):\n",
    "        \"\"\"\n",
    "        get all free positions (those not occupied by any player)\n",
    "        \"\"\"\n",
    "        free = []\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if(self.board[i][j]) == 0:   \n",
    "                    free.append((i, j))\n",
    "        return free\n",
    "    \n",
    "    def is_same(self, p, i, j, di, dj):\n",
    "        \"\"\"\n",
    "        if all numbers in a row/col/diagonal are same\n",
    "        \"\"\"\n",
    "        for k in range(self.size):\n",
    "            if self.board[i][j] != p:\n",
    "                return False\n",
    "            i += di\n",
    "            j += dj\n",
    "        return True\n",
    "    \n",
    "    def is_winner(self, player):\n",
    "        \"\"\"\n",
    "        return True if this player has won the game\n",
    "        \"\"\"\n",
    "        # check rows\n",
    "        for i in range(self.size):\n",
    "            if self.is_same(player, i, 0, 0, 1):\n",
    "                return True\n",
    "        # check columns\n",
    "        for j in range(self.size):\n",
    "            if self.is_same(player, 0, j, 1, 0):\n",
    "                return True\n",
    "        # main diagonal\n",
    "        if self.is_same(player, 0, 0, 1, 1):\n",
    "            return True\n",
    "        # secondary diagonal\n",
    "        if self.is_same(player, 0, self.size-1, 1, -1):\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def is_draw(self):\n",
    "        \"\"\"\n",
    "        returns True if the game has ended in draw\n",
    "        \"\"\"\n",
    "        return len(self.get_free_positions()) == 0\n",
    "            \n",
    "    \n",
    "    def get_winner(self):\n",
    "        \"\"\"\n",
    "        return P1 if player 1 wins, P2 if player 2 wins, 0 if draw, None if not yet finished\n",
    "        \"\"\"\n",
    "        if self.is_winner(P1):\n",
    "            return P1\n",
    "        elif self.is_winner(P2):\n",
    "            return P2\n",
    "        elif self.is_draw():\n",
    "            return 0\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def get_rewards(self, winner):\n",
    "        \"\"\"\n",
    "        return reward when game ends: (reward for first player, reward for second player)\n",
    "        \"\"\"\n",
    "        if winner == P1:\n",
    "            return (1, 0)\n",
    "        elif winner == P2:\n",
    "            return (0, 1)\n",
    "        else:\n",
    "            return (0.1, 0.5)   # player 2 gets more reward for draw\n",
    "    \n",
    "    def update(self, action, player):\n",
    "        self.board[action[0]][action[1]] = player.player_idx\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        reset game after finishing episode\n",
    "        \"\"\"\n",
    "        self.board = np.zeros((self.size, self.size), dtype=int)\n",
    "        \n",
    "    def state_action_hash(self, action, player):\n",
    "        \"\"\"\n",
    "        get hash for (state, action) pair for Q function\n",
    "        \"\"\"\n",
    "        board = self.board.copy()\n",
    "        board[action[0]][action[1]] = player\n",
    "        return hash(str(board))\n",
    "        \n",
    "    def play_episode(self):\n",
    "        turn = 0\n",
    "        while True:\n",
    "            if turn % 2 == 0:\n",
    "                action = self.player1.select_action(self)\n",
    "                self.update(action, self.player1)\n",
    "            else:\n",
    "                action = self.player2.select_action(self)\n",
    "                self.update(action, self.player2)\n",
    "            winner = self.get_winner()\n",
    "            if winner is not None:\n",
    "                reward = self.get_rewards(winner)\n",
    "                self.player1.propagate_return(reward[0])\n",
    "                self.player2.propagate_return(reward[1])\n",
    "                self.player1.reset()\n",
    "                self.player2.reset()\n",
    "                self.reset()\n",
    "                break\n",
    "            turn += 1\n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def play_episode_human(self):\n",
    "        turn = 0\n",
    "        while True:\n",
    "            if turn % 2 == 0:\n",
    "                print('AI turn!')\n",
    "                action = self.player1.select_action(self)\n",
    "                self.update(action, self.player1)\n",
    "            else:\n",
    "                print('Your turn!')\n",
    "                action = self.player2.select_action(self)\n",
    "                self.update(action, self.player2)\n",
    "            self.print_board()\n",
    "            winner = self.get_winner()\n",
    "            if winner is not None:\n",
    "                if winner == P1:\n",
    "                    print('AI wins!')\n",
    "                elif winner == P2:\n",
    "                    print('You win!')\n",
    "                else:\n",
    "                    print('Draw!')\n",
    "                break\n",
    "            turn += 1\n",
    "    \n",
    "    def print_board(self):\n",
    "        print('-------------')\n",
    "        for i in range(self.size):\n",
    "            s = '|'\n",
    "            for j in range(self.size):\n",
    "                if self.board[i][j] == P1:\n",
    "                    token = 'x'\n",
    "                elif self.board[i][j] == P2:\n",
    "                    token = 'o'\n",
    "                else:\n",
    "                    token = '-'\n",
    "                s += ' ' + token + ' |'\n",
    "            print(s)\n",
    "            print('-------------')\n",
    "            \n",
    "    \n",
    "    def play(self, episodes):\n",
    "        for i in range(episodes):\n",
    "            print('--------------Episode {}------------'.format(i))\n",
    "            print('Episode Reward:', self.play_episode())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, idx):\n",
    "        self.states = []\n",
    "        self.state_values = {}\n",
    "        self.player_idx = idx\n",
    "        self.learning_rate = LEARNING_RATE\n",
    "        self.explore_rate = EXPLORE_RATE\n",
    "        self.explore_decay = EXPLORE_DECAY\n",
    "        self.gamma = GAMMA\n",
    "    \n",
    "    def select_action(self, game):\n",
    "        \"\"\"\n",
    "        Select action given a Game state\n",
    "        \"\"\"\n",
    "        options = game.get_free_positions()\n",
    "        action = None\n",
    "        if np.random.uniform(0, 1) <= self.explore_rate:\n",
    "            # Exploration\n",
    "            action = options[np.random.choice(len(options))]\n",
    "        else:\n",
    "            # Exploitation\n",
    "            max_reward = -1e8\n",
    "            for a in options:\n",
    "                h = game.state_action_hash(a, self.player_idx)\n",
    "                if h in self.state_values:\n",
    "                    reward = self.state_values[h]\n",
    "                else:\n",
    "                    reward = 0\n",
    "                if reward >= max_reward:\n",
    "                    max_reward = reward\n",
    "                    action = a\n",
    "        self.states.append(game.state_action_hash(action, self.player_idx))\n",
    "        return action \n",
    "    \n",
    "    def propagate_return(self, reward):\n",
    "        \"\"\"\n",
    "        back-propagate the returns for state-actions visited during this episode\n",
    "        \"\"\"\n",
    "        for s in reversed(self.states):\n",
    "            if s not in self.state_values:\n",
    "                self.state_values[s] = 0\n",
    "            self.state_values[s] += self.learning_rate * (reward - self.state_values[s])\n",
    "            reward *= self.gamma\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        reset states and lower explore rate\n",
    "        \"\"\"\n",
    "        self.states = []\n",
    "        # self.explore_rate *= self.explore_decay\n",
    "        \n",
    "    def save_policy(self, fname):\n",
    "        \"\"\"\n",
    "        store policy\n",
    "        \"\"\"\n",
    "        with open(fname, 'wb') as handle:\n",
    "            pickle.dump(self.state_values, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    def load_policy(self, fname):\n",
    "        \"\"\"\n",
    "        load policy\n",
    "        \"\"\"\n",
    "        with open(fname, 'rb') as handle:\n",
    "            self.state_values = pickle.load(handle)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer:\n",
    "    def __init__(self, idx):\n",
    "        self.player_idx = idx\n",
    "    \n",
    "    def select_action(self, game):\n",
    "        \"\"\"\n",
    "        Select action given a Game state\n",
    "        \"\"\"\n",
    "        options = game.get_free_positions()\n",
    "        while True:\n",
    "            row = int(input('Enter row:'))\n",
    "            col = int(input('Enter col:'))\n",
    "            if (row, col) in options:\n",
    "                return (row, col)\n",
    "            else:\n",
    "                print('Invalid row/column!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Player(P1)\n",
    "p2 = Player(P2)\n",
    "game = Game(N, p1, p2)\n",
    "game.play(50000)\n",
    "p1.save_policy('tictactoe_p1.pickle')\n",
    "p2.save_policy('tictactoe_p2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Player(P1)\n",
    "p1.load_policy('tictactoe_p1.pickle')\n",
    "p1.explore_rate = 0\n",
    "p2 = HumanPlayer(P2)\n",
    "game = Game(N, p1, p2)\n",
    "game.play_episode_human()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
